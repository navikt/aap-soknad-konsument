apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: aap-soknad-konsument-alerts
  labels:
    team: aap
    app: aap-soknad-konsument
  namespace: aap
spec:
  receivers:
    slack:
      channel: '#aap-github'
  alerts:
    - alert: aap-soknad-konsument-app-nede
      expr: kube_deployment_status_replicas_unavailable{deployment="aap-soknad-konsument",job="kubernetes-service-endpoints"} > 0
      for: 5m
      description: "\{{ $labels.app }} har utilgjengelige podder i \{{ $labels.kubernetes_namespace }}"
      action: "`kubectl describe pod -l app={{ $labels.deployment }} -n \{{ $labels.namespace }}` for events og `kubectl get pods -l app=\{{ $labels.deployment }} -n \{{ $labels.namespace }}` for å se feilende podder"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: aap-soknad-konsument-kontinuerlig-restart
      expr: sum(increase(kube_pod_container_status_restarts_total{container=~"aap-soknad-konsument"}[5m])) by (container) > 2
      for: 2m
      description: "\{{ $labels.container }} har restartet flere ganger de siste 5 minuttene!"
      action: "Se `kubectl describe pod \{{ $labels.container }}` for events, og `kubectl logs \{{ $labels.container }}` for logger"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: aap-soknad-konsument-mangler-metrikker
      expr: absent(up{app=~"aap-soknad-konsument",job="kubernetes-pods"})
      for: 2m
      description: "\{{ $labels.app }} rapporterer ingen metrikker i \{{ $labels.kubernetes_namespace }}"
      action: "Sjekk om \{{ $labels.app }} i \{{ $labels.kubernetes_namespace }} er oppe"
      sla: respond within 1h, during office hours
      severity: danger
    - alert: høy feilrate i logger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="aap-soknad-konsument",log_level=~"Error"}[10m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="aap-soknad-konsument"}[10m]))) > 15
      for: 5m
      action: "<https://logs.adeo.no/goto/4dcb5f43d53e90212240667e3e609df4|Check logs>"